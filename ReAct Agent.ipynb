{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "31a03af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in /Users/ronithummaluru/opt/anaconda3/lib/python3.8/site-packages (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ronithummaluru/opt/anaconda3/lib/python3.8/site-packages (from groq) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ronithummaluru/opt/anaconda3/lib/python3.8/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ronithummaluru/opt/anaconda3/lib/python3.8/site-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/ronithummaluru/opt/anaconda3/lib/python3.8/site-packages (from groq) (1.10.12)\n",
      "Requirement already satisfied: sniffio in /Users/ronithummaluru/opt/anaconda3/lib/python3.8/site-packages (from groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/ronithummaluru/opt/anaconda3/lib/python3.8/site-packages (from groq) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/ronithummaluru/opt/anaconda3/lib/python3.8/site-packages (from anyio<5,>=3.5.0->groq) (3.4)\n",
      "Requirement already satisfied: exceptiongroup in /Users/ronithummaluru/opt/anaconda3/lib/python3.8/site-packages (from anyio<5,>=3.5.0->groq) (1.1.3)\n",
      "Requirement already satisfied: certifi in /Users/ronithummaluru/opt/anaconda3/lib/python3.8/site-packages (from httpx<1,>=0.23.0->groq) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ronithummaluru/opt/anaconda3/lib/python3.8/site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ronithummaluru/opt/anaconda3/lib/python3.8/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0558e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GROQ_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "56f44823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's natural language processing (NLP) landscape, and their importance can be attributed to several factors:\n",
      "\n",
      "1. **Real-time Applications**: Fast language models enable real-time processing and interaction with users, which is essential for applications like:\n",
      "\t* Conversational AI (e.g., chatbots, virtual assistants)\n",
      "\t* Sentiment analysis and feedback systems\n",
      "\t* Language translation and interpretation\n",
      "2. **Scalability**: Fast language models can handle large volumes of data and support massive-scale NLP applications, such as:\n",
      "\t* Social media monitoring and analysis\n",
      "\t* Text classification and filtering for content moderation\n",
      "\t* Language models for question answering and recommendation systems\n",
      "3. **Low-Latency Requirements**: Many NLP applications require rapid response times, making fast language models essential for:\n",
      "\t* Voice-activated assistants (e.g., Alexa, Google Assistant)\n",
      "\t* Real-time language translation for live events or meetings\n",
      "\t* Fast text summarization and extraction for news articles or research papers\n",
      "4. **Energy Efficiency**: Fast language models can reduce energy consumption and carbon footprint, particularly in:\n",
      "\t* Edge AI and IoT devices, where power efficiency is crucial\n",
      "\t* Mobile devices, where fast language models enable efficient language processing\n",
      "5. **Improved User Experience**: Fast language models lead to:\n",
      "\t* Smoother and more natural interactions with AI systems\n",
      "\t* Faster response times, reducing user frustration and improving overall experience\n",
      "6. **Competitive Advantage**: Organizations that deploy fast language models can gain a competitive edge in various industries, such as:\n",
      "\t* Customer service and support\n",
      "\t* Marketing and advertising\n",
      "\t* Healthcare and research\n",
      "7. **Enablement of New Use Cases**: Fast language models can unlock new applications and use cases, such as:\n",
      "\t* Real-time language generation for content creation\n",
      "\t* Fast dialogue systems for gaming and entertainment\n",
      "\t* Real-time text-based analytics for financial trading and market analysis\n",
      "8. **Research and Development**: Fast language models can accelerate research and development in NLP, leading to:\n",
      "\t* Faster iteration and experimentation\n",
      "\t* Improved model performance and accuracy\n",
      "\t* New breakthroughs and innovations in language understanding and generation\n",
      "9. **Cost Savings**: Fast language models can reduce computational costs and infrastructure requirements, leading to:\n",
      "\t* Lower operational expenses\n",
      "\t* Increased efficiency and productivity\n",
      "10. **Future-Proofing**: As NLP technology continues to evolve, fast language models will be essential for staying competitive and addressing emerging challenges, such as:\n",
      "\t* Handling increasing volumes of data\n",
      "\t* Adapting to new languages and dialects\n",
      "\t* Addressing concerns around bias and fairness in AI systems\n",
      "\n",
      "In summary, fast language models are critical for driving innovation, improving user experiences, and enabling real-time applications in various industries.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-70b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "14022ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    # Initializes the agent\n",
    "    def __init__(self, client, system):\n",
    "        self.client = client\n",
    "        # Initializes the system message containing the ReAct loop *Thought, Action, Observation*\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system is not None:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": self.system})\n",
    "    \n",
    "    # Called whenever the user calls on the agent    \n",
    "    def __call__(self, message=\"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def execute(self):    \n",
    "        completion = client.chat.completions.create(\n",
    "            messages=self.messages,\n",
    "            model=\"llama3-70b-8192\",\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c4433f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct system prompt instructing the model how to iterate thouroughly until an answer is found\n",
    "system_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "get_planet_mass:\n",
    "e.g. get_planet_mass: Earth\n",
    "returns weight of the planet in kg\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the mass of Earth times 2?\n",
    "Thought: I need to find the mass of Earth\n",
    "Action: get_planet_mass: Earth\n",
    "PAUSE \n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 5.972e24\n",
    "\n",
    "Thought: I need to multiply this by 2\n",
    "Action: calculate: 5.972e24 * 2\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this: \n",
    "\n",
    "Observation: 1,1944×10e25\n",
    "\n",
    "If you have the answer, output it as the Answer.\n",
    "\n",
    "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
    "\n",
    "Now it's your turn:\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d524c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools accessible for the Agent\n",
    "def calculate(operation):\n",
    "    return eval(operation)\n",
    "\n",
    "def get_planet_mass(planet: str) -> float:\n",
    "    planet = planet.lower()\n",
    "    if planet == \"earth\":\n",
    "        return 5.972e24\n",
    "    elif planet == \"jupiter\":\n",
    "        return 1.898e27\n",
    "    elif planet == \"mars\":\n",
    "        return 6.39e23\n",
    "    elif planet == \"mercury\":\n",
    "        return 3.285e23\n",
    "    elif planet == \"neptune\":\n",
    "        return 1.024e26\n",
    "    elif planet == \"saturn\":\n",
    "        return 5.683e26\n",
    "    elif planet == \"uranus\":\n",
    "        return 8.681e25\n",
    "    elif planet == \"venus\":\n",
    "        return 4.867e24\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d0edb",
   "metadata": {},
   "source": [
    "## Going through Agent Loop Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "62b05665",
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_expert = Agent(client=client, system=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "af66f4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to find the mass of Earth\n"
     ]
    }
   ],
   "source": [
    "result = planet_expert(\"what is the mass of the earth times 5?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df71acc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\ncalculate:\\ne.g. calculate: 4 * 7 / 3\\nRuns a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\\n\\nget_planet_mass:\\ne.g. get_planet_mass: Earth\\nreturns weight of the planet in kg\\n\\nExample session:\\n\\nQuestion: What is the mass of Earth times 2?\\nThought: I need to find the mass of Earth\\nAction: get_planet_mass: Earth\\nPAUSE \\n\\nYou will be called again with this:\\n\\nObservation: 5.972e24\\n\\nThought: I need to multiply this by 2\\nAction: calculate: 5.972e24 * 2\\nPAUSE\\n\\nYou will be called again with this: \\n\\nObservation: 1,1944×10e25\\n\\nIf you have the answer, output it as the Answer.\\n\\nAnswer: The mass of Earth times 2 is 1,1944×10e25.\\n\\nNow it's your turn:\"},\n",
       " {'role': 'user', 'content': 'what is the mass of the earth times 5?'},\n",
       " {'role': 'assistant', 'content': 'Thought: I need to find the mass of Earth'}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planet_expert.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8dab1cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: get_planet_mass: Earth\n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "result = planet_expert()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8d6d54c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.972e+24\n"
     ]
    }
   ],
   "source": [
    "observation = get_planet_mass(\"Earth\")\n",
    "print(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "260fc134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: calculate: 5.972e24 * 5\n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "next_prompt = f\"Observation: {observation}\"\n",
    "result = planet_expert(next_prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7a3d94bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9860000000000004e+25\n"
     ]
    }
   ],
   "source": [
    "observation = calculate(\"5.972e24 * 5\")\n",
    "print(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "511ee91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The mass of the earth times 5 is 2.9860000000000004e+25.\n"
     ]
    }
   ],
   "source": [
    "next_prompt = f\"Observation: {observation}\"\n",
    "result = planet_expert(next_prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c7627c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\ncalculate:\\ne.g. calculate: 4 * 7 / 3\\nRuns a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\\n\\nget_planet_mass:\\ne.g. get_planet_mass: Earth\\nreturns weight of the planet in kg\\n\\nExample session:\\n\\nQuestion: What is the mass of Earth times 2?\\nThought: I need to find the mass of Earth\\nAction: get_planet_mass: Earth\\nPAUSE \\n\\nYou will be called again with this:\\n\\nObservation: 5.972e24\\n\\nThought: I need to multiply this by 2\\nAction: calculate: 5.972e24 * 2\\nPAUSE\\n\\nYou will be called again with this: \\n\\nObservation: 1,1944×10e25\\n\\nIf you have the answer, output it as the Answer.\\n\\nAnswer: The mass of Earth times 2 is 1,1944×10e25.\\n\\nNow it's your turn:\"},\n",
       " {'role': 'user', 'content': 'what is the mass of the earth times 5?'},\n",
       " {'role': 'assistant', 'content': 'Thought: I need to find the mass of Earth'},\n",
       " {'role': 'assistant', 'content': ''},\n",
       " {'role': 'assistant', 'content': 'Action: get_planet_mass: Earth\\nPAUSE'},\n",
       " {'role': 'user', 'content': 'Observation: 5.972e+24'},\n",
       " {'role': 'assistant', 'content': 'Thought: I need to multiply this by 5'},\n",
       " {'role': 'user', 'content': 'Observation: 5.972e+24'},\n",
       " {'role': 'assistant', 'content': 'Action: calculate: 5.972e24 * 5\\nPAUSE'},\n",
       " {'role': 'user', 'content': 'Observation: 2.9860000000000004e+25'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Answer: The mass of the earth times 5 is 2.9860000000000004e+25.'}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planet_expert.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eae6d3",
   "metadata": {},
   "source": [
    "## Automating Agent Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9f5add8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def agent_loop(max_iterations, system, query):\n",
    "    agent = Agent(client=client, system=system_prompt)\n",
    "    tools = ['calculate', 'get_planet_mass']\n",
    "    next_prompt = query\n",
    "    i = 0\n",
    "    while i < max_iterations:\n",
    "        i += 1\n",
    "        result = agent(next_prompt)\n",
    "        print(result)\n",
    "        \n",
    "        if \"PAUSE\" in result and \"Action\" in result:\n",
    "            # Finds action name (function to use) and parameters\n",
    "            action = re.findall(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE)\n",
    "            chosen_tool = action[0][0]\n",
    "            arg = action[0][1]\n",
    "            \n",
    "            if chosen_tool in tools:\n",
    "                result_tool = eval(f\"{chosen_tool}('{arg}')\")\n",
    "                next_prompt = f\"Observation: {result_tool}\"\n",
    "            else:\n",
    "                next_prompt = \"Observation: Tool not found\"\n",
    "                \n",
    "        print(next_prompt)\n",
    "        continue\n",
    "        \n",
    "        if \"Answer\" in result:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "579bc0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to find the mass of Earth and the mass of Mars.\n",
      "What is the mass of the Earth plus the mass of Mars times 8?\n",
      "Action: get_planet_mass: Earth\n",
      "PAUSE\n",
      "Observation: 5.972e+24\n",
      "Thought: Now that I have the mass of Earth, I need to find the mass of Mars and then multiply it by 8.\n",
      "Observation: 5.972e+24\n",
      "Action: get_planet_mass: Mars\n",
      "PAUSE\n",
      "Observation: 6.39e+23\n",
      "Thought: I now have the mass of Mars, I need to multiply it by 8.\n",
      "Observation: 6.39e+23\n",
      "Action: calculate: 6.39e+23 * 8\n",
      "PAUSE\n",
      "Observation: 5.112e+24\n",
      "Thought: Now I have the mass of Mars times 8, I need to add the mass of Earth.\n",
      "Observation: 5.112e+24\n",
      "Action: calculate: 5.972e+24 + 5.112e+24\n",
      "PAUSE\n",
      "Observation: 1.1084e+25\n",
      "Thought: I have the final answer!\n",
      "\n",
      "Answer: The mass of the Earth plus the mass of Mars times 8 is 1.1084e+25.\n",
      "Observation: 1.1084e+25\n",
      "Answer: The mass of the Earth plus the mass of Mars times 8 is 1.1084e+25.\n",
      "Observation: 1.1084e+25\n"
     ]
    }
   ],
   "source": [
    "agent_loop(max_iterations=10, system=system_prompt, query=\"What is the mass of the Earth plus the mass of Mars times 8?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
